{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd071cd8744bffe79c19cada91101a76e63722b871e2ba3e6782be94fc6c9ba9fa8",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "71cd8744bffe79c19cada91101a76e63722b871e2ba3e6782be94fc6c9ba9fa8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib.pyplot import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalach</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63</td>\n      <td>1</td>\n      <td>3</td>\n      <td>145</td>\n      <td>233</td>\n      <td>1</td>\n      <td>0</td>\n      <td>150</td>\n      <td>0</td>\n      <td>2.3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>37</td>\n      <td>1</td>\n      <td>2</td>\n      <td>130</td>\n      <td>250</td>\n      <td>0</td>\n      <td>1</td>\n      <td>187</td>\n      <td>0</td>\n      <td>3.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41</td>\n      <td>0</td>\n      <td>1</td>\n      <td>130</td>\n      <td>204</td>\n      <td>0</td>\n      <td>0</td>\n      <td>172</td>\n      <td>0</td>\n      <td>1.4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>56</td>\n      <td>1</td>\n      <td>1</td>\n      <td>120</td>\n      <td>236</td>\n      <td>0</td>\n      <td>1</td>\n      <td>178</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>57</td>\n      <td>0</td>\n      <td>0</td>\n      <td>120</td>\n      <td>354</td>\n      <td>0</td>\n      <td>1</td>\n      <td>163</td>\n      <td>1</td>\n      <td>0.6</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 127
    }
   ],
   "source": [
    "df = pd.read_csv('heart.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "age           int64\n",
       "sex           int64\n",
       "cp            int64\n",
       "trestbps      int64\n",
       "chol          int64\n",
       "fbs           int64\n",
       "restecg       int64\n",
       "thalach       int64\n",
       "exang         int64\n",
       "oldpeak     float64\n",
       "slope         int64\n",
       "ca            int64\n",
       "thal          int64\n",
       "target        int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 128
    }
   ],
   "source": [
    "df.shape\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.9521966 ,  0.68100522,  1.97312292, ..., -2.27457861,\n",
       "        -0.71442887, -2.14887271],\n",
       "       [-1.91531289,  0.68100522,  1.00257707, ..., -2.27457861,\n",
       "        -0.71442887, -0.51292188],\n",
       "       [-1.47415758, -1.46841752,  0.03203122, ...,  0.97635214,\n",
       "        -0.71442887, -0.51292188],\n",
       "       ...,\n",
       "       [ 1.50364073,  0.68100522, -0.93851463, ..., -0.64911323,\n",
       "         1.24459328,  1.12302895],\n",
       "       [ 0.29046364,  0.68100522, -0.93851463, ..., -0.64911323,\n",
       "         0.26508221,  1.12302895],\n",
       "       [ 0.29046364, -1.46841752,  0.03203122, ..., -0.64911323,\n",
       "         0.26508221, -0.51292188]])"
      ]
     },
     "metadata": {},
     "execution_count": 129
    }
   ],
   "source": [
    "\n",
    "\n",
    "# y (output) is our target \n",
    "# y is matrix with length x.row (is equals X.shape[0]) and 1 column\n",
    "Y = df['target'].values.reshape(X.shape[0], 1)\n",
    "X = df.drop([\"target\"], axis=1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "X.shape\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationFunction():\n",
    "    \n",
    "    def __init__(self, z):\n",
    "        self.z = z\n",
    "\n",
    "    def relu(self, z):\n",
    "        \"\"\"\n",
    "        The ReLu activation function is equals 0 where values less than zero. (x=0 when x<=0 and x=x whan x>0)\n",
    "        \"\"\"\n",
    "        return np.maximum(0, z)\n",
    "\n",
    "    def sigmoid (self, z):\n",
    "        \"\"\"\n",
    "        The sigmoid function takes in real numbers in any range and return output between 0 and 1.\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def d_sigmoid(self, z):\n",
    "        \"\"\"\n",
    "        The derivative of sigmoid function\n",
    "        \"\"\"\n",
    "        return (1 - self.sigmoid(z)) * self.sigmoid(z)\n",
    "\n",
    "    def tanh (self, z):\n",
    "        \"\"\"\n",
    "        The range of the tanh function is from (-1 to 1).\n",
    "        \"\"\"\n",
    "        return np.tanh(z)\n",
    "\n",
    "    def d_tanh(self, z):\n",
    "        \"\"\"\n",
    "        The derivative of tanh function\n",
    "        \"\"\"\n",
    "        return 1 - np.power(np.self.tanh(z), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossFunction():\n",
    "\n",
    "    def __init__(self, y, a):\n",
    "        self.y = y\n",
    "        self.a = a\n",
    "\n",
    "    def cross_entropy_loss(self, y, a):\n",
    "        \"\"\"\n",
    "        For a binary classification task (i.e. C=2), the cross-entropy loss function (-sum i[1-2] y1*log(y_predict)) becomes like return formula.\n",
    "        1/len(y) and np.sum mean that return the average loss with respect to all the inputs. That is, the combined loss from all the samples\n",
    "        and not the individual losses.\n",
    "        \"\"\"\n",
    "        return -1 / len(y) * (np.sum(np.multiply(y, np.log(a)) + np.multiply((1 - y), np.log(1 - a))))\n",
    "\n",
    "\n",
    "    def d_cross_entropy_loss(self, y, a):\n",
    "        \"\"\"\n",
    "        The derivative of Cross Entropy function function\n",
    "        \"\"\"\n",
    "        return (a - y)/(a*(1 - a))\n",
    "\n",
    "\n",
    "    def mse(self, y, a):\n",
    "        \"\"\"\n",
    "        Mean square error is measured as the average of squared difference between predictions and actual observations.\n",
    "        \"\"\"\n",
    "        return 1/len(y) * np.sum(np.power((y - a), 2))\n",
    "\n",
    "\n",
    "    def d_mse(self, y, a):\n",
    "        \"\"\"\n",
    "        The derivative of MSE function\n",
    "        \"\"\"\n",
    "        return a-y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gradient(LossFunction):\n",
    "   \n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "\n",
    "    def grad_W_mse(self, x, y):\n",
    "        \"\"\"\n",
    "        The function updating the gradients using mean squared error loss for W\n",
    "        x is input data or previous activation\n",
    "        Cost = (a-y)^2\n",
    "        a = sigmoid(z)\n",
    "        z = w*x + b\n",
    "        D_cost/D_waight = D_cost/D_a  is (d_mse)   D_a/D_z  is (d_sigmoid)   D_z/D_w  is (x)\n",
    "        Return The gradient for D_cost/D_waight \n",
    "        \"\"\"\n",
    "        perceptron = self.perceptron(x)\n",
    "        y_predict = self.sigmoid(perceptron)\n",
    "        return self.d_mse(y, y_predict) * self.d_sigmoid(perceptron) * x \n",
    "\n",
    "\n",
    "    def grad_B_mse(self, x, y):\n",
    "        \"\"\"\n",
    "        The function updating the gradients using mean squared error loss for b\n",
    "        x is input data or previous activation\n",
    "        Cost = (a-y)^2\n",
    "        a = sigmoid(z)\n",
    "        z = w*x + b\n",
    "        D_cost/D_waight = D_cost/D_a  is (d_mse)   D_a/D_z  is (d_sigmoid)   D_z/D_b  is (x)\n",
    "        Return The gradient for D_cost/D_waight \n",
    "        \"\"\"\n",
    "\n",
    "        # I use the function grad_w_mse and divide to x because in formula D_cost/D_b  D_z/D_w=0 and D_z/D_b = 1 \n",
    "        return self.grad_W_mse(x, y) / x\n",
    "\n",
    "\n",
    "    def grad_W_ce(self, x, y):\n",
    "        \"\"\"\n",
    "        The function updating the gradients using cross entropy loss for W\n",
    "        x is input data or previous activation\n",
    "        \"\"\"\n",
    "        y_predict = self.sigmoid(self.perceptron(x))\n",
    "\n",
    "        if y == 0:\n",
    "            return y_predict * x\n",
    "        elif y == 1:\n",
    "            return -1 * (1 - y_predict) * x\n",
    "\n",
    "\n",
    "    def grad_B_ce(self, x, y):\n",
    "        \"\"\"\n",
    "        The function updating the gradients using mean squared error loss for b\n",
    "        x is input data or previous activation\n",
    "        \"\"\"\n",
    "        y_predict = self.sigmoid(self.perceptron(x))\n",
    "        \n",
    "        if y == 0:\n",
    "            return y_predict \n",
    "        elif y == 1:\n",
    "            return -1 * (1 - y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworks (ActivationFunction, Gradient):\n",
    "    def __init__(self):\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "\n",
    "\n",
    "    def perceptron(self, x):\n",
    "        \"\"\"\n",
    "        x is input data in the fist layer, for the second layers is neurons.\n",
    "        return Z which equals w*x+b or w*a+b\n",
    "        \"\"\"\n",
    "        return np.dot(x, self.w.T) + self.b\n",
    "    \n",
    "\n",
    "    def fit(self, X, Y, iters= 2000, lr = 0.01, loss_fn = \"mse\"):\n",
    "        \"\"\"\n",
    "        X is input\n",
    "        Y is Labels\n",
    "        loss_fn is choose which loss function use\n",
    "        The function uptade weights and biases\n",
    "        \"\"\"\n",
    "\n",
    "        self.w = np.random.randn(1, X.shape[1])\n",
    "        self.b = 0\n",
    "\n",
    "        for iter in range(iters):\n",
    "            dw = 0\n",
    "            db = 0\n",
    "            for x, y in zip(X, Y):\n",
    "                if loss_fn == \"mse\":\n",
    "                    dw += self.grad_W_mse(x, y)\n",
    "                    db += self.grad_B_mse(x, y)\n",
    "                elif loss_fn == \"ce\":\n",
    "                    dw += self.grad_W_ce(x, y)\n",
    "                    db += self.grad_B_ce(x, y)\n",
    "\n",
    "            size = X.shape[1]\n",
    "            self.w -= lr * dw / size\n",
    "            self.b -= lr * db / size\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        The function compute the forward pass (z and a) of each input with the trained model \n",
    "        and send back a numpy array which contains the predicted value of each input data.\n",
    "        \"\"\"\n",
    "        Y_predict = []\n",
    "        \n",
    "        for x in X:\n",
    "            y_predict = self.sigmoid(self.perceptron(x))\n",
    "            for i in range(len(y_predict)):\n",
    "                if y_predict[i]>=0.5:\n",
    "                    y_predict[i]=1\n",
    "                else:\n",
    "                    y_predict[i]=0\n",
    "            Y_predict.append(y_predict)\n",
    "        \n",
    "        return np.array(Y_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.506578947368421\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetworks ()\n",
    "nn.fit(X_train, y_train)\n",
    "\n",
    "y_predict_test = nn.predict(X_test)\n",
    "y_test = y_test.reshape(-1)\n",
    "y_predict_test = y_predict_test.reshape(-1)\n",
    "\n",
    "accuracy = 0\n",
    "for i in range(len(y_test)):\n",
    "    if int(y_predict_test[i]) == y_test[i]:\n",
    "    \n",
    "        accuracy +=1\n",
    "prob = accuracy / len(y_test)\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}